import os
import openai
import logging
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters
from datetime import datetime, timedelta

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ë–æ—Ç –∞–∫—Ç–∏–≤–µ–Ω. –û–∂–∏–¥–∞—é –∑–∞–¥–∞—á–∏ üß†")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text
    await update.message.reply_text(f"–ü—Ä–∏–Ω—è—Ç–æ: {text} (–≤ –±—É–¥—É—â–µ–º —è —ç—Ç–æ —Ä–∞—Å–ø–∞—Ä—Å—é)")

def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == '__main__':
    main()
@bot.message_handler(commands=['ai'])
def handle_ai(message):
    msg = bot.send_message(message.chat.id, "–ù–∞–ø–∏—à–∏ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∫ ChatGPT:")
    bot.register_next_step_handler(msg, process_ai_prompt)

def process_ai_prompt(message):
    prompt = message.text
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–æ–º–æ–≥–∞–µ—à—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞—á–∏."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        reply = response['choices'][0]['message']['content']
        bot.send_message(message.chat.id, reply)
    except Exception as e:
        bot.send_message(message.chat.id, f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
